{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "name = '2017-07-03-scrape_binstar'\n",
    "title = \"Binstar/conda package stats\"\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# with open('creative_commons.txt', 'r') as f:\n",
    "#    html = f.read()\n",
    "    \n",
    "# html = '''\n",
    "# <small>\n",
    "# <p> This post was written as an IPython notebook.\n",
    "#  It is available for <a href='https://ocefpaf.github.com/python4oceanographers/downloads/notebooks/%s.ipynb'>download</a>\n",
    "#  or as a static <a href='https://nbviewer.ipython.org/url/ocefpaf.github.com/python4oceanographers/downloads/notebooks/%s.ipynb'>html</a>.</p>\n",
    "# <p></p>\n",
    "# %s''' % (name, name, html)\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "hour = datetime.utcnow().strftime('%H:%M')\n",
    "comments=\"true\"\n",
    "\n",
    "date = '-'.join(name.split('-')[:3])\n",
    "slug = '-'.join(name.split('-')[3:])\n",
    "\n",
    "metadata = dict(title=title,\n",
    "                date=date,\n",
    "                hour=hour,\n",
    "                comments=comments,\n",
    "                slug=slug,\n",
    "                name=name)\n",
    "\n",
    "markdown = \"\"\"Title: {title}\n",
    "date:  {date} {hour}\n",
    "comments: {comments}\n",
    "slug: {slug}\n",
    "\n",
    "{{% notebook {name}.ipynb cells[1:] %}}\n",
    "\"\"\".format(**metadata)\n",
    "\n",
    "# content = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, '{}.md'.format(name)))\n",
    "# with open('{}'.format(content), 'w') as f:\n",
    "#     f.writelines(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "[Conda](http://conda.pydata.org/docs/intro.html) and\n",
    "[binstar](https://binstar.org/) are changing the packaging world of Python.\n",
    "Conda made it easy to install re-locatable python binaries that where hard\n",
    "to build, while binstar provides a \"Linux repository-like system\"\n",
    "(or if you are younger than me an AppStore-like system) to host custom binaries.\n",
    "\n",
    "Taking advantage of that [IOOS](http://www.ioos.noaa.gov/) created a binstar\n",
    "[channel](https://binstar.org/ioos) with Met-ocean themed packages for Windows,\n",
    "Linux and MacOS.  Note that, if you are using Red Hat Enterprise Linux or Centos you\n",
    "should use the [rhel6 channel](https://binstar.org/ioos-rhel6) to avoid the\n",
    "[GLIBC problem](https://groups.google.com/a/continuum.io/forum/#!topic/conda/_MGxU8vOBPw).\n",
    "\n",
    "All the conda-recipes are open and kept in a GitHub\n",
    "[repository](https://github.com/ioos/conda-recipes). (And accepting PRs ;-)\n",
    "\n",
    "In this post I will not show how to install and configure conda with this channel.\n",
    "It has been done already [here](https://ocefpaf.github.io/python4oceanographers/blog/2014/06/23/virtual_env/)\n",
    "and\n",
    "[here](https://github.com/ioos/conda-recipes/wiki).  Is this post I will scrape\n",
    "the binstar channel stats to evaluate how the channel is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "First some handy functions to parse the dates, the package names, and\n",
    "to same all the data into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def todatetime(ul_str):\n",
    "    upload = re.compile(r'((?P<year>\\d+) years?)?( and )?((?P<month>\\d+) months?)?( and )?((?P<day>\\d+) days?)?( and )?((?P<hour>\\d+) hours?)?( and )?((?P<min>\\d+) minutes?)?(.*)ago')\n",
    "    yr = mo = dy = hr = mn = 0\n",
    "    mobj = upload.match(ul_str)\n",
    "    if mobj:\n",
    "        if mobj.group('year'):\n",
    "            yr = int(mobj.group('year'))\n",
    "        if mobj.group('month'):\n",
    "            mo = int(mobj.group('month'))\n",
    "        if mobj.group('day'):\n",
    "            dy = int(mobj.group('day'))\n",
    "        if mobj.group('hour'):\n",
    "            hr = int(mobj.group('hour'))\n",
    "        if mobj.group('min'):\n",
    "            mn = int(mobj.group('min'))\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected period {!r}\".format(ul_str))\n",
    "\n",
    "    delta = relativedelta(years=yr, months=mo, days=dy, hours=hr, minutes=mn)\n",
    "    return date.today() - delta\n",
    "\n",
    "\n",
    "def parse_name(cell):\n",
    "    name = cell.text.strip().split('/')\n",
    "    if len(name) != 2:\n",
    "        name = cell.text.strip().split('\\\\')\n",
    "    arch = '{}'.format(name[0].split()[1])\n",
    "    name = '{}'.format(name[1].split('.tar.bz2')[0])\n",
    "    return arch, name\n",
    "\n",
    "\n",
    "def get_page(package, page):\n",
    "    url = \"https://anaconda.org/psi4/{}/files?page={}\".format\n",
    "    r = requests.get(url(package, page))\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    table = soup.find(\"table\", class_=\"full-width\")\n",
    "    \n",
    "    downloads, uploaded, platforms, names = [], [], [], []\n",
    "    for row in table.findAll('tr'):\n",
    "        col = row.findAll('td')\n",
    "        #print('COL: ', col)\n",
    "        if len(col) == 8:\n",
    "            downloads.append(int(col[6].text.strip()))\n",
    "            uploaded.append(todatetime(col[4].text.strip()))\n",
    "            platform, name = parse_name(col[3])\n",
    "            platforms.append(platform)\n",
    "            names.append(name)\n",
    "            #print downloads[-1], uploaded[-1], platforms[-1], names[-1]\n",
    "    return downloads, uploaded, platforms, names\n",
    "\n",
    "\n",
    "def get_df(package):\n",
    "    downloads, uploaded, platforms, names = [], [], [], []\n",
    "    for page in range(1, 15):\n",
    "        dn, up, pf, nm = get_page(package, page)\n",
    "        print(len(nm), end=' ')\n",
    "        downloads.extend(dn)\n",
    "        uploaded.extend(up)\n",
    "        platforms.extend(pf)\n",
    "        names.extend(nm)\n",
    "        if len(nm) != 50:\n",
    "            break\n",
    "    else:\n",
    "        print(\"Insufficient pages or packages in multiple of 50 which may lead to inflated download counts.\")\n",
    "    \n",
    "    df = DataFrame(data=np.c_[platforms, names, uploaded, downloads],\n",
    "                   columns=['platform', 'name', 'uploaded', 'downloads'])\n",
    "    df['uploaded'] = pd.to_datetime(df['uploaded'])\n",
    "    df.set_index('uploaded', inplace=True, drop=True)\n",
    "    df['downloads'] = df['downloads'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "All the data we need is in the `repodata.json` file.  There isn't an API\n",
    "to access that via the command line (yet), that is why we need to scrape\n",
    "it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from requests import HTTPError\n",
    "from pandas import Panel, read_json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "\n",
    "json = \"https://conda.anaconda.org/psi4/linux-64/repodata.json\"\n",
    "df = read_json(json)\n",
    "\n",
    "packages = sorted(set(['-'.join(pac.split('-')[:-2]) for pac in df.index]))\n",
    "packages = [pkg for pkg in packages if pkg]\n",
    "packages = [u'psi4', u'chemps2', u'dftd3', u'pcmsolver', u'v2rdm_casscf', u'libint', u'erd', u'simint', u'dkh', u'gdma', u'gcp', u'libefp', 'libxc']\n",
    "\n",
    "dfs = dict()\n",
    "for pac in packages:\n",
    "    try:\n",
    "        print('\\n', pac, ': ', end='')\n",
    "        dfs.update({pac: get_df(pac)})\n",
    "    except HTTPError:\n",
    "        continue\n",
    "        \n",
    "#print(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now let's split the various platforms and compute total number of downloads\n",
    "for each package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_plat_total(df):\n",
    "    package = dict()\n",
    "    \n",
    "    for plat in ['linux-64', 'osx-64']:  #, 'win-32', 'win-64']:\n",
    "        # all time\n",
    "        #sset = df.loc[:].query('platform == \"{}\"'.format(plat))\n",
    "        # before 1.0  # 5 Jul 2017 - no longer any good b/c I thinned out the pkgs\n",
    "        #sset = df.loc['2016-7-4':].query('platform == \"{}\"'.format(plat))\n",
    "        # after 1.0\n",
    "        #sset = df.loc[:'2016-7-4'].query('platform == \"{}\"'.format(plat))\n",
    "        # after 1.1\n",
    "        sset = df.loc[:'2017-5-16'].query('platform == \"{}\"'.format(plat))\n",
    "        print(sset)  # nicely formatted output\n",
    "        total = sset.sum()\n",
    "        package.update({plat: total['downloads']})\n",
    "    return package\n",
    "\n",
    "packages = dict()\n",
    "for pac in dfs.keys():\n",
    "    df = dfs[pac]\n",
    "    packages.update({pac: get_plat_total(df)})\n",
    "\n",
    "for pac in dfs.keys():\n",
    "    print('{:<15}: {:<10} {:<6} {:<10} {:<6} {:<10} {:<6}'.format(pac, \n",
    "          'linux-64', packages[pac]['linux-64'],\n",
    "          'osx-64', packages[pac]['osx-64'],\n",
    "          'total', packages[pac]['linux-64'] + packages[pac]['osx-64']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = DataFrame.from_dict(packages).T\n",
    "df['sum'] = df.T.sum()\n",
    "df.sort('sum', ascending=False, inplace=True)\n",
    "df.drop('sum', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "And here is the result,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stride = 19 # 19 x 5 = 95\n",
    "# stride = len(packages)\n",
    "kw = dict(kind='bar', stacked=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 3))\n",
    "ax = df.ix[:stride].plot(ax=ax, **kw)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(11, 3))\n",
    "# ax = df.ix[stride:stride*2].plot(ax=ax, **kw)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(11, 3))\n",
    "# ax = df.ix[stride*2:stride*3].plot(ax=ax, **kw)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(11, 3))\n",
    "# ax = df.ix[stride*3:stride*4].plot(ax=ax, **kw)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(11, 3))\n",
    "# ax = df.ix[stride*4:stride*5].plot(ax=ax, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# df['win'] = df['win-32'] + df['win-64']\n",
    "# total = df[['linux-64', 'osx-64', 'win']].sum()\n",
    "\n",
    "total = df[['linux-64', 'osx-64']].sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "ax = total.plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Right now it is hard to make sense of the data.  That is because some\n",
    "downloads might be a direct download or an indirect download via a package\n",
    "dependency.  Also, our own build system downloads the dependencies when\n",
    "building new or when updating the packages in the channel.  One conclusion\n",
    "that we may take from this is that the Windows packages are as popular the\n",
    "Linux packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', 1500)\n",
    "\n",
    "# packagesY = dict()\n",
    "# #dates = pd.date_range('1/1/2016', periods=12)\n",
    "# #print 'keys', dfs.keys(), dates\n",
    "# for pac in dfs.keys():\n",
    "#     print '<<<  {}  >>>'.format(pac)\n",
    "#     df = dfs[pac]\n",
    "#     df.sort_index(inplace=True)\n",
    "#     #print 'df\\n', df\n",
    "#     #print 'cols', df.axes\n",
    "#     #df.plot(title=pac)\n",
    "#     df['cumulative_downloads']=df['downloads'].cumsum()\n",
    "#     print df\n",
    "#     df.plot(title=pac, figsize=(15, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
